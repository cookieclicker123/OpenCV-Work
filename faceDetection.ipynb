{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff36ee2-b852-40c7-b9dd-28307d31de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bad7ffec-20e1-4d41-9ef6-757324f4514f",
   "metadata": {},
   "source": [
    "Function to download and extract zip files.\n",
    "\n",
    "Defines a function download_and_unzip with parameters url (the URL of the file to download) and save_path (the local path to save the downloaded file).\n",
    "Within the function:\n",
    "\n",
    "Prints a message indicating the start of the download and extraction process.\n",
    "Downloads the ZIP file from the specified url to save_path using urlretrieve.\n",
    "Tries to:\n",
    "Open the downloaded ZIP file using ZipFile.\n",
    "Extract all contents of the ZIP file to the directory specified by save_path.\n",
    "Prints \"Done\" upon successful extraction.\n",
    "Catches any exceptions, printing an error message with the exception details if the ZIP file is invalid or extraction fails.\n",
    "Outside the function:\n",
    "\n",
    "Sets URL to the direct download link of the ZIP file hosted on Dropbox.\n",
    "Constructs asset_zip_path, a path to save the ZIP file, using the current working directory and a filename.\n",
    "Checks if the ZIP file already exists at asset_zip_path.\n",
    "If it doesn't, calls download_and_unzip with URL and asset_zip_path to download and extract the ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2275349e-f9af-4a1e-acc9-a0ed2497b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url, save_path):\n",
    "    print(f\"Downloading and extracting assests....\", end=\"\")\n",
    "\n",
    "    # Downloading zip file using urllib package.\n",
    "    urlretrieve(url, save_path)\n",
    "\n",
    "    try:\n",
    "        # Extracting zip file using the zipfile package.\n",
    "        with ZipFile(save_path) as z:\n",
    "            # Extract ZIP file contents in the same directory.\n",
    "            z.extractall(os.path.split(save_path)[0])\n",
    "\n",
    "        print(\"Done\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\nInvalid file.\", e)\n",
    "\n",
    "\n",
    "URL = r\"https://www.dropbox.com/s/efitgt363ada95a/opencv_bootcamp_assets_12.zip?dl=1\"\n",
    "\n",
    "asset_zip_path = os.path.join(os.getcwd(), f\"opencv_bootcamp_assets_12.zip\")\n",
    "\n",
    "# Download if assest ZIP does not exists.\n",
    "if not os.path.exists(asset_zip_path):\n",
    "    download_and_unzip(URL, asset_zip_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52866dd6-8e44-4a91-b2f3-6cd58c2af21b",
   "metadata": {},
   "source": [
    "Video capture setup.\n",
    "\n",
    "Initializes a variable s with 0, typically representing the default webcam device ID for cv2.VideoCapture.\n",
    "Checks if the script has been passed command-line arguments (len(sys.argv) > 1):\n",
    "If yes, assigns the first argument (sys.argv[1]) to s. This allows for dynamic assignment of the video source, such as a different webcam device ID or a video file path.\n",
    "Initializes video capture by creating a cv2.VideoCapture object named source, using s as the source. This object is used to capture video frames from the specified source.\n",
    "Sets win_name to \"Camera Preview\", a string used to identify the window that will display the video.\n",
    "Creates a named window using cv2.namedWindow with win_name and sets the window flag to cv2.WINDOW_NORMAL. This allows the window size to be adjusted manually, facilitating the display of the camera preview or video playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca171ad-01dc-465c-85a1-3bb2f9e49587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"-f\"\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "if len(sys.argv) > 1:\n",
    "    s = sys.argv[1]\n",
    "\n",
    "source = cv2.VideoCapture(s)\n",
    "\n",
    "win_name = \"Camera Preview\"\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c33053b-0750-48f2-8382-c12372896032",
   "metadata": {},
   "source": [
    "Deep learning model setup.\n",
    "\n",
    "Loads a pre-trained deep learning model using cv2.dnn.readNetFromCaffe:\n",
    "deploy.prototxt: Specifies the network architecture.\n",
    "res10_300x300_ssd_iter_140000_fp16.caffemodel: Contains the trained weights of the model. This particular model is designed for face detection, optimized for speed and accuracy.\n",
    "Sets model input parameters:\n",
    "in_width and in_height: Both set to 300, indicating the size to which each frame will be resized before being passed through the network. This size matches the model's required input dimensions for optimal performance.\n",
    "mean: A list of mean subtraction values [104, 117, 123] to be subtracted from each channel of the input images. Mean subtraction helps in reducing illumination differences and is a common pre-processing step in deep learning for images.\n",
    "conf_threshold: Set to 0.7, representing the minimum confidence threshold for detecting faces. Detections with confidence values below this threshold will be ignored. This helps in reducing false positives, ensuring that only detections with a high degree of confidence are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28d70b8-76f4-462e-89e7-222cd3648ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "# Model parameters\n",
    "in_width = 300\n",
    "in_height = 300\n",
    "mean = [104, 117, 123]\n",
    "conf_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae7830-3b6a-49d2-959c-da7552a89508",
   "metadata": {},
   "source": [
    "Face Detection and Display Loop.\n",
    "\n",
    "Video Frame Processing Loop:\n",
    "\n",
    "Continuously captures frames from the video source until the \"Esc\" key (key code 27) is pressed.\n",
    "Reads frames using source.read(), checking if frames are successfully captured. If not, breaks the loop.\n",
    "Flips each frame horizontally for a mirror effect using cv2.flip.\n",
    "Calculates the frame's width and height for later use in scaling detection bounding boxes.\n",
    "Face Detection:\n",
    "\n",
    "Transforms the captured frame into a blob suitable for input into the deep learning model, considering frame dimensions and mean values.\n",
    "Sets the transformed blob as input to the loaded neural network (net) and performs inference to detect faces.\n",
    "Iterates over detections, filtering out detections with a confidence score below a predefined threshold to reduce false positives.\n",
    "Drawing Bounding Boxes and Labels:\n",
    "\n",
    "For each valid detection, calculates the bounding box coordinates based on the frame dimensions and draws rectangles around detected faces with a green color.\n",
    "Displays a label with the confidence score near each detected face, using a white background rectangle for better visibility.\n",
    "Measures and displays the inference time for performance evaluation, indicating how fast the model predicts faces in the frame.\n",
    "Display and Cleanup:\n",
    "\n",
    "Shows the processed frame in a window named \"Camera Preview\".\n",
    "Releases the video source and destroys the window after exiting the loop to free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5db1dc6-c9e2-46ad-a838-2b50f5631ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 13:55:36.942 Python[16469:936142] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "while cv2.waitKey(1) != 27:\n",
    "    has_frame, frame = source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_width = frame.shape[1]\n",
    "\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (in_width, in_height), mean, swapRB=False, crop=False)\n",
    "    # Run a model\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x_left_bottom = int(detections[0, 0, i, 3] * frame_width)\n",
    "            y_left_bottom = int(detections[0, 0, i, 4] * frame_height)\n",
    "            x_right_top = int(detections[0, 0, i, 5] * frame_width)\n",
    "            y_right_top = int(detections[0, 0, i, 6] * frame_height)\n",
    "\n",
    "            cv2.rectangle(frame, (x_left_bottom, y_left_bottom), (x_right_top, y_right_top), (0, 255, 0))\n",
    "            label = \"Confidence: %.4f\" % confidence\n",
    "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (x_left_bottom, y_left_bottom - label_size[1]),\n",
    "                (x_left_bottom + label_size[0], y_left_bottom + base_line),\n",
    "                (255, 255, 255),\n",
    "                cv2.FILLED,\n",
    "            )\n",
    "            cv2.putText(frame, label, (x_left_bottom, y_left_bottom), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = \"Inference time: %.2f ms\" % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
    "    cv2.imshow(win_name, frame)\n",
    "\n",
    "source.release()\n",
    "cv2.destroyWindow(win_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b45294-fc97-47af-b26d-71246077c3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
